{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01348ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U kaleido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4342b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5107a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'jupyter' #colab\n",
    "render = 'image' #image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13131316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.offline as pyo\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot\n",
    "\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "if mode == 'colab':\n",
    "    import cufflinks as cf\n",
    "    cf.go_offline()\n",
    "    init_notebook_mode(connected=False)\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Config for Colab\n",
    "def configure_plotly_browser_state():\n",
    "    import IPython\n",
    "    display(IPython.core.display.HTML('''\n",
    "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
    "        <script>\n",
    "          requirejs.config({\n",
    "            paths: {\n",
    "              base: '/static/base',\n",
    "              plotly: 'https://cdn.plot.ly/plotly-1.5.1.min.js?noext',\n",
    "            },\n",
    "          });\n",
    "        </script>\n",
    "        '''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2321b021",
   "metadata": {},
   "outputs": [],
   "source": [
    "if render == 'image':\n",
    "    import plotly.io as pio\n",
    "    pio.renderers.default = 'png'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfaf8ba",
   "metadata": {},
   "source": [
    "# Statistics - Hypothesis Testing\n",
    "\n",
    "\n",
    "Hypothesis the process of testing an idea using statistics. An idea must be testable. For example, if we have a idea 'the price of apples in a city is expensive' - this idea is not testable unless we have something to compare it with. But if we change the idea to 'the price of apples in a city is greater than or equal to $\\$$1.75' - in this case we can test the idea since we can compare it with a price. So, the idea then becomes a hypothesis.\n",
    "\n",
    "To perform hypothesis testing, we follow the steps mentioned below:\n",
    "\n",
    "- Generate a testable idea\n",
    "\n",
    "- Design an experiment to test the hypothesis\n",
    "\n",
    "- Collect the result of the experiment\n",
    "\n",
    "- Analyze the result\n",
    "\n",
    "Hypothesis are of two types:\n",
    "\n",
    "- **Null Hypothesis:** In hypothesis testing, null hypothesis is the hypothesis that we want to test. For our above example, the null hypothesis will be 'the price of apples in a city is greater than or equal to 1.75'. It is denoted by $H_0$\n",
    "\n",
    "- **Alternate Hypothesis:** All results that are not included in null hypothesis falls under alternate hypothesis. For our above example, the alternate hypothesis will be 'the price of apples in a city is less than $\\$$1.75'. It is dentoted by $H_A$ or $H_1$.\n",
    "\n",
    "\\begin{equation}\n",
    "H_0 : \\mu_0 \\geq 1.75 \\\\\n",
    "H_1: \\mu_1 < 1.75\n",
    "\\end{equation}\n",
    "\n",
    "During a test, we try to disprove the null hypothesis. $H_0$ is considered true until proved otherwise. \n",
    "\n",
    "**In statistics, null hypothesis is the statement that we are trying to reject.**\n",
    "\n",
    "Hypothesis testing are of two types:\n",
    "\n",
    "- **Two-tailed test:** In hypothesis testing, if a test allow for the possibility of an effect in two direction, then the test is known as two-tailed test.\n",
    "\n",
    "As for example, if our null hypothesis is - The mean salary of a data scientist is $\\$$ 100,000. In this case, we consider the probability distribution of the salaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866f62d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_hypothesis = 100_000\n",
    "samples = np.random.normal(loc=null_hypothesis, scale=10_000, size=10000)\n",
    "plt.figure()\n",
    "plt.hist(samples, density=True)\n",
    "plt.grid()\n",
    "plt.xlabel(\"Salary ($)\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b7dad6",
   "metadata": {},
   "source": [
    "The alternative hypothesis is - The mean salary is either greater than or less than $\\$$ 100,000. If the null hypothesis is wrong, the actual mean salary can either be on the left side of 100,000 in the distribution or it can be in the right side. Since the effect can be on two sides, these type of test is known as two-tailed test. It is also known as two-sided test.\n",
    "\n",
    "- **One-tailed test:** In hypothesis testing, if a test allow for the possibility of an effect in one direction, then the test is known as one-tailed test.\n",
    "\n",
    "For example, if the null hypothesis is, 'The mean salary of data scientist is **greater than or equal to** $\\$$ 100,00' - in this case if the null hypothesis is wrong then the actual mean will be somewhere on left side of $\\$$ 100,000 in the distribution. So, these type of test is known as one-tailed test or one-sided test.\n",
    "\n",
    "## Signficance Level\n",
    "\n",
    "In statistics, we are try to reject a null hypotheis. However, there is always a small possibility that we make an error and reject a null hypothesis that is true. The probability of rejecting a null hypothesis that is true, is known as significance level. It is denoted by $\\alpha$.\n",
    "\n",
    "It is the complement of confidence level. The typical values for $\\alpha$ are 0.01, 0.05, and 0.1. This value is selected during the experiment based on the requirements of the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c771e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "096ee8d5",
   "metadata": {},
   "source": [
    "### Z-Test (Two-tailed test)\n",
    "\n",
    "Suppose, we have the following hypothesis - The average grade of students in a college is $70\\%$ i.e.\n",
    "\n",
    "\\begin{equation}\n",
    "H_0 : \\mu_0 = 0.70 \\\\\n",
    "H_1: \\mu_1 \\neq 0.70\n",
    "\\end{equation}\n",
    "\n",
    "We assume that the grades are normally distributed. To test this hypothesis we can perform a z-test. The equation of a z-test is as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "Z = \\frac{\\bar{x} - \\mu}{\\frac{s}{\\sqrt{n}}}\n",
    "\\end{equation}\n",
    "\n",
    "Here,\n",
    "- $\\bar{x}$ is the sample mean\n",
    "- $\\mu$ is the population mean i.e. $70\\%$\n",
    "- $s$ is the standard deviation of the sample\n",
    "- $n$ is the sample size\n",
    "- $\\frac{s}{\\sqrt{n}}$ is the standard error\n",
    "\n",
    "If the mean of our sample is close to zero, then the value of 'Z' is close to zero. So, lower value of z means that we accept the null hypothesis. But what should the significance level be. Suppose, we assume that the signficance level is 0.05. In that case the graph will will look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ef63d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "x = np.linspace(-4, 4, 1000)\n",
    "density = stats.norm.pdf(x)\n",
    "critical_value = stats.norm.ppf(1 - alpha/2)\n",
    "left_indices = np.where(x <= -critical_value)[0]\n",
    "right_indices = np.where(x >= critical_value)[0]\n",
    "\n",
    "plt.figure()\n",
    "plt.fill(x, density, color='blue')\n",
    "plt.fill_between(x[left_indices], density[left_indices], color='green')\n",
    "plt.fill_between(x[right_indices], density[right_indices], color='green')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b948a370",
   "metadata": {},
   "source": [
    "For a standard normal distribution, the mean is 0 and the standard deviation is 1. So, for $alpha=0.05$, the z-score will be \n",
    "\\begin{equation}\n",
    "Table(1 - \\frac{\\alpha}{2}) = Table(0.975) - 1.9 + 0.6 = 1.96\n",
    "\\end{equation}\n",
    "\n",
    "Since the test is a two-tailed test, if our calculated grade lies in a region outside some value on the left or in a region outside some value on the right, we will consider the null hypothesis to be as false. We calculated the critical value to be 2.5. Therefore, if our result is below $-1.96$ or above $1.96$ we will consider the null hypothesis to be false. The region is colored in green in the above distribution. This region is known as **rejection region** because we will reject the null hypothesis if our result falls within this region.\n",
    "\n",
    "To perform the test we take the following steps:\n",
    "\n",
    "- Create a distribution of sample grades.\n",
    "- We compute the 'Z statistic' using the equation $\\frac{\\bar{x} - \\mu}{\\frac{s}{\\sqrt{n}}}$\n",
    "- We choose a significance level $\\alpha$.\n",
    "- We calculate the critical value.\n",
    "\n",
    "If the z-statistic result is below the minimum critical value or above the maximum critical value, we consider the null hypothesis to be false. Otherwise we consider it to be correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3812c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_z_score(sample_mean, hypothesized_mean, sample_standard_deviation, sample_size):\n",
    "    standard_error = sample_standard_deviation/np.sqrt(sample_size)\n",
    "    return (sample_mean - hypothesized_mean)/standard_error\n",
    "\n",
    "hypothesis_mean_grade = 0.70\n",
    "sample_student_grades = [0.4, 0.6, 0.5, 0.1, 0.4, 0.7, 0.9, 0.8, 0.85, 0.9, 0.7, 0.63]\n",
    "\n",
    "# Calculate sample mean\n",
    "sample_mean = np.mean(sample_student_grades)\n",
    "sample_standard_deviation = np.std(sample_student_grades)\n",
    "sample_size = len(sample_student_grades)\n",
    "significance_level = 0.05\n",
    "\n",
    "z_score = calculate_z_score(sample_mean, hypothesis_mean_grade, sample_standard_deviation, sample_size)\n",
    "critical_value = stats.norm.ppf(1-(significance_level)/2)\n",
    "\n",
    "print(f\"The z-score is {z_score} and the critical value is {critical_value}\")\n",
    "accepted = -critical_value <= z_score <= critical_value\n",
    "result = \"accept\" if accepted else \"reject\"\n",
    "result_range = \"within\" if accepted else \"outside\"\n",
    "print(f\"The z-score is {result_range} the range of critical value. So, with a significance level of {significance_level}, we {result} the null hypothesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9426ef61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ae25706",
   "metadata": {},
   "source": [
    "### Z-Test (One-tailed test)\n",
    "\n",
    "Suppose we have the following hypothesis - The average salary of a data scientist is more than $\\$$125,000. So, the hypothesis becomes:\n",
    "\n",
    "\\begin{equation}\n",
    "H_0 : \\mu_0 \\geq \\$125,000 \\\\\n",
    "H_1: \\mu_1 < \\$125,000\n",
    "\\end{equation}\n",
    "\n",
    "If the value of our calculation is greater than or equal to 125,000, we accept the null hypothesis. However, if our result is less than $x = 125,000$ where 'x' is a critical value threshold, then we reject the null hypothesis. So, this time the rejection region is only on left of the distribution i.e. it is on one side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68390a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "x = np.linspace(-4, 4, 1000)\n",
    "density = stats.norm.pdf(x)\n",
    "critical_value = stats.norm.ppf(1 - alpha/2)\n",
    "left_indices = np.where(x <= -critical_value)[0]\n",
    "\n",
    "plt.figure()\n",
    "plt.fill(x, density, color='blue')\n",
    "plt.fill_between(x[left_indices], density[left_indices], color='green')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0e3067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2581ba2b",
   "metadata": {},
   "source": [
    "If we consider a significance level ($\\alpha$) of 0.05, the equation to calculate the critical value from the z-table will be \n",
    "\n",
    "\\begin{equation}\n",
    "Table(1 - \\alpha) = Table(0.95) - 1.6 + 0.04 = 1.64\n",
    "\\end{equation}\n",
    "\n",
    "Since the test is one-tailed we have considered $1-\\alpha$ instead of $1-\\frac{\\alpha}{2}$. Therefore, if our z-score is below $-1.64$, we will reject the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2844e28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis_mean_salary = 125_000\n",
    "sample_salaries = [70_000, 50_000, 75_000, 80_000, 90_000, 80_000, 70_000, 65_000, 80_000]\n",
    "\n",
    "\n",
    "# Calculate sample mean\n",
    "sample_mean = np.mean(sample_salaries)\n",
    "sample_standard_deviation = np.std(sample_salaries)\n",
    "sample_size = len(sample_salaries)\n",
    "significance_level = 0.05\n",
    "\n",
    "z_score = calculate_z_score(sample_mean, hypothesis_mean_salary, sample_standard_deviation, sample_size)\n",
    "critical_value = stats.norm.ppf(1 - significance_level)\n",
    "\n",
    "print(f\"The z-score is {z_score} and the critical value is {critical_value}\")\n",
    "accepted = z_score >= -critical_value\n",
    "result = \"accept\" if accepted else \"reject\"\n",
    "result_range = \"within\" if accepted else \"outside\"\n",
    "print(f\"The z-score is {result_range} the range of critical value. So, with a significance level of {significance_level}, we {result} the null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ae05ec",
   "metadata": {},
   "source": [
    "In the above example, our z-score is $-14.3$ and the critical value is $-1.64$. Since, the z-score falls outside the range of our critical value we can reject the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa38261",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7daab04",
   "metadata": {},
   "source": [
    "## Type I Errors\n",
    "\n",
    "\n",
    "**Type I** error is an error that we make when we **reject a true null** hypothesis. This is also known as **false positive**. \n",
    "\n",
    "The probability of making this error is $\\alpha$ i.e. the level of significance. If we choose a wrong significance level then this error may occur. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee85b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_minus_alpha = np.arange(0, 1, 0.001)\n",
    "critical_values = stats.norm.ppf(one_minus_alpha)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(1- one_minus_alpha, critical_values, label='critical value')\n",
    "ax.set_xlabel(\"Significance level, alpha\")\n",
    "ax.set_ylabel(\"Critical value, z\")\n",
    "\n",
    "plt.grid()\n",
    "plt.title(\"Significance level VS Critical value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902d5cc1",
   "metadata": {},
   "source": [
    "If we choose a very low significance level, the value of $1-\\alpha$ increases. If this increases, then the critical value increases. \n",
    "As the critical value increases, the range of acceptance region becomes wider as the rejection region becomes narrower. \n",
    "\n",
    "If the range of acceptance region is wider, then there is a higher possibility that the true population mean (predicted by null hypothesis) may within the acceptance range. \n",
    "\n",
    "\n",
    "## Type II Errors\n",
    "\n",
    "\n",
    "**Type II** error is an error that we make when we **accept a false null** hypothesis. This is also known as **false negative**. \n",
    "\n",
    "The probability of making this error is $\\beta$. This type of error occurs due to sample size and variance. The probability of rejecting a false null hypothesis is $1-\\beta$. This error can be reduced by increasing the sample size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0839b39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e3fe148",
   "metadata": {},
   "source": [
    "## Test for Mean with known population variance\n",
    "\n",
    "In this example we will test the following hypothesis - The average salary of a data scientis is equal to $\\$$ 92,000.\n",
    "\n",
    "\\begin{equation}\n",
    "H_0 : \\mu_0 = \\$ 92,000 \\\\\n",
    "H_1: \\mu_1 \\neq \\$ 92,000\n",
    "\\end{equation}\n",
    "\n",
    "Our sample dataset contains the salary of data scientists. The population variance $\\mu$ will be equal to the value of our null hypothesis i.e $\\$$ 92,000. Since the population variance is known, we will consider the population standard deviation $\\sigma$ to be $\\$$ 15,000.\n",
    "\n",
    "Since the critical value can affect two sides of a distribution, this is a two-tailed test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5c836e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('data_scientist_salary.xlsx')\n",
    "df.info()\n",
    "df.head()\n",
    "\n",
    "population_standard_deviation = 15_000\n",
    "population_mean_of_interest = 92_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe4762c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(df['Salary'], density=True)\n",
    "plt.grid()\n",
    "plt.title(\"Probability Distribution of Salary\")\n",
    "plt.xlabel(\"Salary\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bbe37a",
   "metadata": {},
   "source": [
    "### Task 1 - Standardize the distribution\n",
    "\n",
    "First we need to standardize the distribution by calculating the Z-score. The equation to calculate the Z-score is as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "Z = \\frac{\\bar{x} - \\mu}{\\frac{\\sigma}{\\sqrt{n}}}\n",
    "\\end{equation}\n",
    "\n",
    "Here,\n",
    "- '$\\bar{x}$' is the sample mean\n",
    "- '$\\mu$' is the mean of interest from the null hypothesis\n",
    "- '$\\sigma$' is the population standard deviation\n",
    "- 'n' is the sample size\n",
    "\n",
    "In this way we obtain a distribution with mean $x - \\mu$ and standard deviation '1'. Therefore, we can then compare the data with the Z-table. As the data of Z-table is for a standard normal distribution with mean 0 and standard deviation 1, the closer our value $\\bar{x}-\\mu$ is to zero, the more accurate is the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610a374f",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_error = population_standard_deviation/np.sqrt(len(df))\n",
    "print(f\"Standard error is {standard_error}\")\n",
    "\n",
    "z_score = (np.mean(df['Salary']) - population_mean_of_interest)/standard_error\n",
    "\n",
    "print(f\"The Z-score is {z_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485fc6b9",
   "metadata": {},
   "source": [
    "### Task 2 - Compare the Z-score with critical value\n",
    "\n",
    "Now we will calculate the critical value 'z' from the Z-statistics table using a significance level of 0.05. If the z-score is less than -z or greater than +z, then we will reject the null hypothesis. Otherwise, we will accept the null hypothesis. Since, this is a two-tailed test, the data from z-table will be calculated using $1-\\frac{\\alpha}{2}$.\n",
    "\n",
    "**Note**\n",
    "\n",
    "We use the absolute value $|Z|$ of the z-score instead of the actual value since some z-statistics tables do not contain data for negative values and it is easier to compare the positive values. So, if we use the absolute value to calculate the critical value, we can just check whether the z-score is greater than critical value and omit the test for negative range. That is because $-Z < -z$ is the same as $Z > z$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9262b231",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "critical_value = stats.norm.ppf(1 - (alpha/2))\n",
    "print(f\"The critical value is {critical_value}\")\n",
    "\n",
    "accepted = np.abs(z_score) <= np.abs(critical_value)\n",
    "result = \"accept\" if accepted else \"reject\"\n",
    "result_range = \"within\" if accepted else \"outside\"\n",
    "print(f\"The z-score is {result_range} the range of critical value. So, with a significance level of {alpha*100}%, we {result} the null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee3ff95",
   "metadata": {},
   "source": [
    "As we reduce the value of significance level i.e. increase the confidence interval, the acceptance range of the distribution becomes wider as the critical value decreases. So, the possibility of accepting the null hypothesis also increases. As for example, we increase the confidence level to 99.9\\%, the significance level becomes $1-0.999=0.001$. In that case,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71673dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.001\n",
    "critical_value = stats.norm.ppf(1 - (alpha/2))\n",
    "print(f\"The critical value is {critical_value}\")\n",
    "\n",
    "accepted = np.abs(z_score) <= np.abs(critical_value)\n",
    "result = \"accept\" if accepted else \"reject\"\n",
    "result_range = \"within\" if accepted else \"outside\"\n",
    "print(f\"The z-score is {result_range} the range of critical value. So, with a significance level of {alpha*100}%, we {result} the null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66694f63",
   "metadata": {},
   "source": [
    "Therefore, if we keep decreasing the signifcance level, there **may** come a point when we can no longer reject the null hypothesis. There is a method to calculate the **significance level below which we can no longer reject the null hypothesis.** We find this by calculating the **P-Value**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039d0dce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "572a4edb",
   "metadata": {},
   "source": [
    "## P-Value\n",
    "\n",
    "This is the minimum value of a significance level of a test **after** which we can no longer reject the null hypothesis. P-value is the last significance level at which we can reject a null hypothesis. Therefore, the higher the P-Value of a test, it is more likely that the null hypothesis is correct.\n",
    "\n",
    "When testing, we calculate the p-value of a distribution. We then choose a signifance level $\\alpha$. If the p-value is lower than $\\alpha$, we can reject the null hypothesis at that significance level because if the value of alpha is lower than p-value only then we can no longer reject the null hypothesis. \n",
    "\n",
    "### Calculating the P-value\n",
    "\n",
    "1. In the above example, our hypothesis was - the average salary of a data scientist is $\\$$ 92,000 and we rejected the hypothesis at a significance level of 5\\%. To calculate the p-value, we first find the z-score of the distribution. In our case the z-score is $2.99$.\n",
    "\n",
    "2. Next we lookup the Z-statistics table and find the cell $c$ whose sum of the row and column header equals to 2.99. If we cannot find such cell, we choose the cell that has the sum nearest to 2.99.\n",
    "\n",
    "3. If the test is two-sided, then $(1-c)*2$ provides us the p-value. If the test is one-sided, then $1-c$ provides us the p-value. \n",
    "\n",
    "\n",
    "For our example, the cell whose sum of row and column header is equal to $2.99$ is $0.9986$. So, the p-value for our example is $(1-0.9986)*2 = 0.0027$. Therefore, **for significance level below 0.2\\%, we can no longer reject our null hypothesis.**\n",
    "\n",
    "**Since the main objective of a test is to reject the null hypothesis, the closer p-value is to zero, the better is the outcome of the test. Usually, p-value with three zeros after the decimal point is considered better since there is a higher chance of rejecting the null hypothesis.**\n",
    "\n",
    "**P-Value is a measure that works for all type of distributions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13320367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81f7058c",
   "metadata": {},
   "source": [
    "## Test for Mean with unknown population variance\n",
    "\n",
    "Let us consider the hypothesis - More than 40\\% of customers of a company opens marketing emails from the company. We are trying to prove that this hypothesis is correct. Since we are trying to prove this point, the opposite statement will become the null hypothesis. In this case the hypothesis becomes:\n",
    "\n",
    "\\begin{equation}\n",
    "H_0 : \\mu_0 \\leq 40\\% \\\\\n",
    "H_1: \\mu_1 > 40\\%\n",
    "\\end{equation}\n",
    "\n",
    "Since the rejection region can be only on one side of the distribution, this is considered a one-tailed test. We will reject the null hypothesis if the significance level is at least 5\\% i.e. $\\alpha=0.05$. We assume that the population open rate of emails is normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2dae81",
   "metadata": {},
   "outputs": [],
   "source": [
    "population_mean_of_interest = 40\n",
    "\n",
    "df = pd.read_excel('email_open_rate.xlsx')\n",
    "df.info()\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff115ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_mean = np.mean(df['Open rate'])\n",
    "standard_deviation = np.std(df['Open rate'])\n",
    "\n",
    "print(f\"The sample mean is {sample_mean:.2f} and the sample standard_deviation is {standard_deviation:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922b5346",
   "metadata": {},
   "source": [
    "### Task 1 - Standardize the distribution\n",
    "\n",
    "**Since we have a small sample and an unknown variance, we will use the T-statistics to test our hypothesis.** \n",
    "\n",
    "The equation to calculate the T-score is as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "T = \\frac{\\bar{x} - \\mu}{\\frac{s}{\\sqrt{n}}}\n",
    "\\end{equation}\n",
    "\n",
    "Here,\n",
    "- '$\\bar{x}$' is the sample mean\n",
    "- '$\\mu$' is the mean of interest from the null hypothesis\n",
    "- '$s$' is the sample standard deviation\n",
    "- 'n' is the sample size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d397c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_error = standard_deviation/np.sqrt(len(df))\n",
    "print(f\"The standard error is {standard_error}\")\n",
    "t_score = (sample_mean - population_mean_of_interest)/standard_error\n",
    "print(f\"The T-score is {t_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3420ef6",
   "metadata": {},
   "source": [
    "Since it is easier to compare using absolute value, we will use the absolute value of the T-Score and critical value for comparison.\n",
    "\n",
    "### Task 2 - Compare the T-score with critical value\n",
    "\n",
    "Now we will calculate the critical value 't' from the T-statistics table using a significance level of 0.05 and $n-1$ degrees of freedom i.e. $10-1=9$ degrees of freedom. If the t-score is less than -t or greater than +t, then we will reject the null hypothesis. Otherwise, we will accept the null hypothesis. Since, this is a one-tailed test, the data from t-table will be calculated using $1-\\alpha$.\n",
    "\n",
    "**Note**\n",
    "\n",
    "We use the absolute value $|T|$ of the t-score instead of the actual value since some t-statistics tables do not contain data for negative values and it is easier to compare the positive values. So, if we use the absolute value to calculate the critical value, we can just check whether the t-score is greater than critical value and omit the test for negative range. That is because $-T < -t$ is the same as $T > t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca136b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "degree_of_freedom = len(df) - 1\n",
    "critical_value = stats.t.ppf(1-alpha, degree_of_freedom)\n",
    "print(f\"The critical value is {critical_value:.2f}\")\n",
    "\n",
    "accepted = np.abs(t_score) <= np.abs(critical_value)\n",
    "result = \"accept\" if accepted else \"reject\"\n",
    "result_range = \"within\" if accepted else \"outside\"\n",
    "print(f\"The t-score is {result_range} the range of critical value. So, with a significance level of {alpha*100}%, we {result} the null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2108e855",
   "metadata": {},
   "source": [
    "Since the T-score is 0.56 is less than the critical value 1.83, we accept the null hypothesis at a significance level of 5\\%.\n",
    "\n",
    "### Task 3 - Calculate P-Value\n",
    "\n",
    "The T-score is 0.56. So, we find the cell in where the index of the row is equal to the degree of freedom and the cell which has the value nearest to the T-score. For our case it is 0.700. So, the P-Value is $1-0.7=0.3$. Since the p-value is greater than the significance level $0.05$, we can accept the null hypothesis. \n",
    "\n",
    "Therefore, at a significance level of 5\\%, the email open rate of the customers is less than or equal to 40\\%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaf151c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41b915a1",
   "metadata": {},
   "source": [
    "## Test for Mean - Dependent Samples\n",
    "\n",
    "Let us consider the hypothesis - The level of magnesium increases after the administration of a medication. We are trying to prove that this hypothesis is correct. Since we are trying to prove this point, the opposite statement will become the null hypothesis. In this case the hypothesis becomes:\n",
    "\n",
    "\\begin{equation}\n",
    "H_0 : \\mu_{after} - \\mu_{before} < 0 \\\\\n",
    "H_1: \\mu_{after} - \\mu_{before} \\geq 0\n",
    "\\end{equation}\n",
    "\n",
    "Since the rejection region can be only on one side of the distribution, this is considered a one-tailed test. We will reject the null hypothesis if the significance level is at least 5\\% i.e. $\\alpha=0.05$. We assume that the population is normally distributed.\n",
    "\n",
    "Let us denote $\\mu_{after} - \\mu_{before}$ as the difference of the population mean $\\mu_{D_0}$ for null hypothesis $H_0$ and $\\mu_{D_1}$ for alternative hypothesis $H_1$. Therefore, the hypothesis becomes:\n",
    "\n",
    "\\begin{equation}\n",
    "H_0 : \\mu_{D_0} < 0 \\\\\n",
    "H_1: \\mu_{D_1} \\geq 0\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6f8e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('blood_magnesium_level.xlsx')\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cbafa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['D'] = df['After'] - df['Before']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8975a53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(df['D'], density=True)\n",
    "plt.grid()\n",
    "plt.title(\"Probability Distribution of difference in magnesium level\")\n",
    "plt.xlabel(\"Difference, D\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6e762b",
   "metadata": {},
   "source": [
    "### Task 1 - Standardize the distribution\n",
    "\n",
    "Since the sample size is small and the population variance is unknown, we will use the T-statistics instead of the Z-statistics. First we need to standardize the distribution by calculating the T-score. The equation to calculate the T-score is as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "T = \\frac{\\bar{x_D} - \\mu_D}{\\frac{s_D}{\\sqrt{n}}}\n",
    "\\end{equation}\n",
    "\n",
    "Here,\n",
    "- '$\\bar{x_D}$' is the sample mean of the differences\n",
    "- '$\\mu_D$' is the mean of interest from the null hypothesis i.e. 0\n",
    "- '$s_D$' is the sample standard deviation of the difference\n",
    "- 'n' is the sample size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e20483e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_mean = np.mean(df['D'])\n",
    "sample_standard_deviation = np.std(df['D'])\n",
    "population_mean_of_interest = 0\n",
    "alpha = 0.05\n",
    "degree_of_freedom = len(df) - 1\n",
    "\n",
    "standard_error = sample_standard_deviation/np.sqrt(len(df))\n",
    "\n",
    "print(f\"The standard error is {standard_error}\")\n",
    "\n",
    "t_score = (sample_mean - population_mean_of_interest)/standard_error\n",
    "\n",
    "print(f\"The T-score is {t_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2f27f6",
   "metadata": {},
   "source": [
    "Since it is easier to compare using absolute value, we will use the absolute value of the T-Score and critical value for comparison.\n",
    "\n",
    "### Task 2 - Compare the T-score with critical value\n",
    "\n",
    "Now we will calculate the critical value 't' from the T-statistics table using a significance level of 0.05 and $n-1$ degrees of freedom i.e. $10-1=9$ degrees of freedom. If the t-score is less than -t or greater than +t, then we will reject the null hypothesis. Otherwise, we will accept the null hypothesis. Since, this is a one-tailed test, the data from t-table will be calculated using $1-\\alpha$.\n",
    "\n",
    "**Note**\n",
    "\n",
    "We use the absolute value $|T|$ of the t-score instead of the actual value since some t-statistics tables do not contain data for negative values and it is easier to compare the positive values. So, if we use the absolute value to calculate the critical value, we can just check whether the t-score is greater than critical value and omit the test for negative range. That is because $-T < -t$ is the same as $T > t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c26502d",
   "metadata": {},
   "outputs": [],
   "source": [
    "critical_value = stats.t.ppf(1-alpha, degree_of_freedom)\n",
    "print(f\"The critical value is {critical_value:.2f}\")\n",
    "\n",
    "accepted = np.abs(t_score) <= np.abs(critical_value)\n",
    "result = \"accept\" if accepted else \"reject\"\n",
    "result_range = \"within\" if accepted else \"outside\"\n",
    "print(f\"The t-score is {result_range} the range of critical value. So, with a significance level of {alpha*100}%, we {result} the null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead88855",
   "metadata": {},
   "source": [
    "Since the critical value is less than the T-score, we reject the null hypothesis. The null hypothesis was - The level of magnesium in blood after the medication reduces i.e. the difference of the magnesium level becomes less than zero.\n",
    "\n",
    "Since this hypothesis is incorrect, we can say that - at a significance level of 5\\%, the level of magnesium in the blood increases or remains the same after administration of the medication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc139d09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a5023db",
   "metadata": {},
   "source": [
    "Since the T-score is 2.419 and is greater than the critical value 1.83, we reject the null hypothesis at a significance level of 5\\%.\n",
    "\n",
    "### Task 3 - Calculate P-Value\n",
    "\n",
    "The T-score is 2.419. So, we find the cell in where the index of the row is equal to the degree of freedom and the cell which has the value nearest to the T-score. For our case it is 2.26. The value of $\\alpha$ for this cell is somewhere between 0.05 and 0.2. Using a p-value calculator the value is approximately 0.024. Therefore, the p-value is 2.4\\%. \n",
    "\n",
    "Since the p-value is less than the significance level, at a significance level of 5\\%, the blood magnesium level of the patients increase or remain the same after medication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb922d69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d15de63",
   "metadata": {},
   "source": [
    "## Test for Mean - Independent Samples (known population variance)\n",
    "\n",
    "In a college we have two different departments: Engineering and Management. Let us consider the hypothesis - on average, the management students outperform the engineering students by 4\\%. We want to prove that the hypothesis is wrong.\n",
    "\n",
    "We can re-formulate the null hypothesis as: The average difference ($\\mu_M - \\mu_E$) between the grade of management ($\\mu_M$) and engineering ($\\mu_E$) students is equal to 4\\%. So, the equation becomes:\n",
    "\n",
    "\\begin{equation}\n",
    "H_0 : \\mu_{M} - \\mu_{E} = 4\\% \\\\\n",
    "H_1: \\mu_{M} - \\mu_{E} \\neq 4\\%\n",
    "\\end{equation}\n",
    "\n",
    "If the difference is either greater than 4 or less than 4, we reject the hypothesis. So, in this case it is a two-sided test. We will reject the null hypothesis if the significance level is at least 5\\% i.e. $\\alpha=0.05$. We assume that the population is normally distributed. We are provided the following population parameters:\n",
    "\n",
    "| - | Engineering | Management | Difference |\n",
    "| --- | --- | --- | --- |\n",
    "| Size | 100 | 70 | - |\n",
    "| Mean | 58\\% | 65\\% | 7\\% |\n",
    "| Population std | 10\\% | 6\\% | -1.23\\% |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f2d747",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size_management = 70\n",
    "sample_size_eng = 100\n",
    "\n",
    "sample_mean_management = 65\n",
    "sample_mean_eng = 58\n",
    "\n",
    "population_std_management = 6\n",
    "population_std_eng = 10\n",
    "\n",
    "population_mean_of_interest = 4\n",
    "alpha = 0.05\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82918382",
   "metadata": {},
   "source": [
    "### Task 1 - Standardize the distribution\n",
    "\n",
    "Since the population variance is known and the sample size is relatively large, we will consider using the Z-statistics. To standardize the variable by calculating the Z-score, we can use the following equation for independent samples with known population variance:\n",
    "\n",
    "\\begin{equation}\n",
    "Z = \\frac{\\bar{x_D} - \\mu_D}{\\sqrt{\\frac{\\sigma^2_M}{n_M} + \\frac{\\sigma^2_E}{n_E}}}\n",
    "\\end{equation}\n",
    "\n",
    "Here,\n",
    "- $\\bar{x_D}$ is equal to $\\bar{x_M} - \\bar{x_E}$\n",
    "\n",
    "- $\\mu_D$ is equal to $\\mu_M - \\mu_E$ which is equal to the estimated mean of our hypothesis i.e. 4\\%.\n",
    "\n",
    "- $\\bar{x_M}$ and $\\bar{x_E}$ are the sample mean of the grades of management and engineering department respectively.\n",
    "\n",
    "- $\\sigma^2_M$ and $\\sigma^2_E$ are the population variance of the grades of management and engineering departments respectively.\n",
    "\n",
    "- $n_M$ and $n_E$ are the sample size of the grades of management and engineering respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f668a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_sample_mean = sample_mean_management - sample_mean_eng\n",
    "standard_error_management = np.square(population_std_management)/sample_size_management\n",
    "standard_error_eng = np.square(population_std_eng)/sample_size_eng\n",
    "\n",
    "print(f\"The difference of the sample mean is {difference_sample_mean}\")\n",
    "print(f\"Standard error of management is {standard_error_management}\")\n",
    "print(f\"Standard error of engineering is {standard_error_eng}\")\n",
    "\n",
    "z_score = (difference_sample_mean - population_mean_of_interest)/ np.sqrt(standard_error_management + standard_error_eng)\n",
    "print(f\"The z-score is {z_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14648dc6",
   "metadata": {},
   "source": [
    "### Task 2 - Compare the Z-score with critical value\n",
    "\n",
    "Now we will calculate the critical value 'z' from the Z-statistics table using a significance level of 0.05. If the z-score is less than -z or greater than +z, then we will reject the null hypothesis. Otherwise, we will accept the null hypothesis. Since, this is a two-tailed test, the data from z-table will be calculated using $1-\\frac{\\alpha}{2}$.\n",
    "\n",
    "**Note**\n",
    "\n",
    "We use the absolute value $|Z|$ of the z-score instead of the actual value since some z-statistics tables do not contain data for negative values and it is easier to compare the positive values. So, if we use the absolute value to calculate the critical value, we can just check whether the z-score is greater than critical value and omit the test for negative range. That is because $-Z < -z$ is the same as $Z > z$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bc0b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "critical_value = stats.norm.ppf(1 - (alpha/2))\n",
    "print(f\"The critical value is {critical_value}\")\n",
    "\n",
    "accepted = np.abs(z_score) <= np.abs(critical_value)\n",
    "result = \"accept\" if accepted else \"reject\"\n",
    "result_range = \"within\" if accepted else \"outside\"\n",
    "print(f\"The z-score is {result_range} the range of critical value. So, with a significance level of {alpha*100}%, we {result} the null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73f6e9f",
   "metadata": {},
   "source": [
    "Since the Z-score is 2.438 and is greater than the critical value 1.96, we reject the null hypothesis at a significance level of 5\\%.\n",
    "\n",
    "### Task 3 - Calculate P-Value\n",
    "\n",
    "The Z-score is 2.438. So, we find the cell whose sum of row and column header equal to the z-score. If we cannot find such value we pick the sum which is nearest to it. Let the value in the cell of the corresponding row and column be 'c'. The p-value is equal to $1-c*2$ since this is a two-sided test. For our case $c=0.9927$. So, the critical value is $1-0.9927*2 =-0.985 $\n",
    "\n",
    "Since the p-value is less than the significance level, at a significance level of 5\\%, the average difference between the grade of management and engineering students are not 4\\% - it is either less or more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0a9c73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9740ce6",
   "metadata": {},
   "source": [
    "## Test for Mean - Independent Samples (unknown population variance and assumed equal)\n",
    "\n",
    "\n",
    "We are trying to find if the price of apple is more expensive in New York than in L.A. We consider that the population variance of the apple price in both cities are the same. We consider the hypothesis - The difference between the average price of apples in New York and L.A is equal to zero. We are trying to reject this null hypothesis. So, the equation becomes:\n",
    "\n",
    "\\begin{equation}\n",
    "H_0 : \\mu_{NY} - \\mu_{LA} = 0 \\\\\n",
    "H_1: \\mu_{NY} - \\mu_{LA} \\neq 0\n",
    "\\end{equation}\n",
    "\n",
    "We do not know the population variance but assume it to be the same. We will consider a significance level of 5\\%. If the difference is either greater than 0 or less than 0, we reject the hypothesis. So, in this case it is a two-sided test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623e57e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('apple_price.xlsx')\n",
    "df.info()\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068deddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_ny = df['NY']\n",
    "samples_la = df['LA'].dropna()\n",
    "\n",
    "sample_mean_ny = np.mean(samples_ny)\n",
    "sample_mean_la = np.mean(samples_la)\n",
    "\n",
    "print(f\"Sample mean- NY: {sample_mean_ny:.2f}, LA: {sample_mean_la:.2f}\")\n",
    "\n",
    "sample_std_ny = np.std(samples_ny)\n",
    "sample_std_la = np.std(samples_la)\n",
    "\n",
    "print(f\"Sample standard deviation- NY: {sample_std_ny:.2f}, LA: {sample_std_la:.2f}\")\n",
    "\n",
    "sample_size_ny = len(samples_ny)\n",
    "sample_size_la = len(samples_la)\n",
    "\n",
    "print(f\"Sample Size - NY: {sample_size_ny}, LA: {sample_size_la}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb157d6",
   "metadata": {},
   "source": [
    "### Task 1 - Standardize the distribution\n",
    "\n",
    "Since the population variance is unknown and the sample size is relatively small, we will consider using the T-statistics. To standardize the variable by calculating the T-score, we can use the following equation for independent samples with unknown population variance but assumed to be the same:\n",
    "\n",
    "\\begin{equation}\n",
    "T = \\frac{\\bar{x_D} - \\mu_D}{\\sqrt{\\frac{\\sigma^2_p}{n_{NY}} + \\frac{\\sigma^2_p}{n_{LA}}}}\n",
    "\\end{equation}\n",
    "\n",
    "Here,\n",
    "- $\\bar{x_D}$ is equal to $\\bar{x_{NY}} - \\bar{x_{LA}}$\n",
    "\n",
    "- $\\mu_D$ is equal to $\\mu_{NY} - \\mu_{LA}$ which is equal to the estimated mean of our hypothesis i.e. 0.\n",
    "\n",
    "- $\\bar{x_{NY}}$ and $\\bar{x_{LA}}$ are the sample mean of the prices of apples in NY and LA respectively.\n",
    "\n",
    "- $\\sigma^2_p$ is the pooled variance.\n",
    "\n",
    "- $n_{NY}$ and $n_{LA}$ are the sample size of dataset of NY and LA respectively.\n",
    "\n",
    "The equation to calculate the pooled variance is as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "s^2_p = \\frac{(n_{NY} - 1) s_{NY}^2 + (n_{LA} - 1) s_{LA}^2}{n_{NY} + n_{LA} - 2}\n",
    "\\end{equation}\n",
    "\n",
    "Here,\n",
    "- $n_{NY}$ and $n_{LA}$ are the sample size of NY and LA respectively.\n",
    "- $s^2_{YA}$ and $s^2_{LA}$ is the variance of the sample NY and LA respectively.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96319caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pooled_variance(sample_size_1, sample_size_2, sample_variance_1, sample_variance_2):\n",
    "    num_1 = (sample_size_1 - 1) * sample_variance_1\n",
    "    num_2 = (sample_size_2 - 1) * sample_variance_2\n",
    "    den = sample_size_1 + sample_size_2 - 2\n",
    "    \n",
    "    return (num_1 + num_2)/den\n",
    "\n",
    "pooled_variance = calculate_pooled_variance(sample_size_ny, sample_size_la, np.square(sample_std_ny), np.square(sample_std_la))\n",
    "\n",
    "print(f\"The pooled variance is {pooled_variance}\")\n",
    "\n",
    "alpha = 0.05\n",
    "mean_population_estimate = 0\n",
    "\n",
    "\n",
    "diff_sample_mean = sample_mean_ny - sample_mean_la\n",
    "print(f\"Difference between sample mean is {diff_sample_mean}\")\n",
    "\n",
    "numerator = diff_sample_mean - mean_population_estimate\n",
    "\n",
    "den1 = pooled_variance/sample_size_ny\n",
    "den2 = pooled_variance/sample_size_la\n",
    "\n",
    "denomenator = np.sqrt(den1 + den2)\n",
    "\n",
    "t_score = numerator/denomenator\n",
    "print(f\"The T-score is {t_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62320cb",
   "metadata": {},
   "source": [
    "### Task 2 - Compare the T-score with critical value\n",
    "\n",
    "Now we will calculate the critical value 't' from the T-statistics table using a significance level of 0.05 and $n_{NY} + n_{LA} - 2$ degrees of freedom i.e. $10+8-2=16$ degrees of freedom. If the t-score is less than -t or greater than +t, then we will reject the null hypothesis. Otherwise, we will accept the null hypothesis. Since, this is a two-tailed test, the data from t-table will be calculated using $1-\\alpha/2$.\n",
    "\n",
    "**Note**\n",
    "\n",
    "We use the absolute value $|T|$ of the t-score instead of the actual value since some t-statistics tables do not contain data for negative values and it is easier to compare the positive values. So, if we use the absolute value to calculate the critical value, we can just check whether the t-score is greater than critical value and omit the test for negative range. That is because $-T < -t$ is the same as $T > t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e72290",
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees_of_freedom = sample_size_ny + sample_size_la - 2\n",
    "critical_value = stats.t.ppf(1-alpha/2, degrees_of_freedom)\n",
    "\n",
    "print(f\"The critical value is {critical_value}\")\n",
    "\n",
    "accepted = np.abs(t_score) <= np.abs(critical_value)\n",
    "result = \"accept\" if accepted else \"reject\"\n",
    "result_range = \"within\" if accepted else \"outside\"\n",
    "print(f\"The t-score is {result_range} the range of critical value. So, with a significance level of {alpha*100}%, we {result} the null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211f359a",
   "metadata": {},
   "source": [
    "Since the T-score is 6.95 and is greater than the critical value 2.12, we reject the null hypothesis at a significance level of 5\\%.\n",
    "\n",
    "**Note: Generally if a Z-score or a T-score is greater than 4, we reject the null hypothesis.**\n",
    "\n",
    "\n",
    "### Task 3 - Calculate P-Value\n",
    "\n",
    "The T-score is 6.95. So, we find the cell in where the index of the row is equal to the degree of freedom and the cell which has the value nearest to the T-score. For our case it is 5.13. The value of $\\alpha$ for this cell is somewhere below 0.0001. Using a p-value calculator the value is approximately 0.0001. Therefore, the p-value is 0.01\\%. \n",
    "\n",
    "Since the p-value is less than the significance level and has three zeros after decimal place, at all level of significance, the price of apples in New York and LA is not the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73f36a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4799bdc",
   "metadata": {},
   "source": [
    "## Note\n",
    "\n",
    "When calculating the scores of samples, we use the mean. However, there may be scenario where some outliers of the sample has very different values that bias the mean. Therefore, we should always check the dataset before we apply these hypothesis testing and ensure that the sample means or variances are not biased. \n",
    "\n",
    "In case of a biased dataset, we can segment the data and then perform the test to ensure that our results match every time. For example, we are calculating the mean difference between the salary of male and female in a company and few females get very high salary compared to other females - these difference in salary for some outliers can bias the dataset and affect our result. In this case we can segment the data into two parts: mean difference between salary of employees below 35 years of age and over 35 years of age. This type of segmentation will help reduce the affect of outliers in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9b5952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ad93dc7",
   "metadata": {},
   "source": [
    "## Excercise\n",
    "\n",
    "We have a dataset containing the salary of 'white' and 'non-white' (ethnic) employees of a company. We want to test if there is a pay gap between the employees based on their ethnicity. \n",
    "\n",
    "**Hypothesis**\n",
    "\n",
    "The difference between the average salary of white and non-white employees is zero. Therefore, the hypothesis is:\n",
    "\n",
    "\\begin{equation}\n",
    "H_0 : \\mu_W - \\mu_N = 0 \\\\\n",
    "H_1: \\mu_W - \\mu_N \\neq 0\n",
    "\\end{equation}\n",
    "\n",
    "- **Significance Level:** We will use a significance level, $\\alpha$ of 0.05.\n",
    "\n",
    "- **Distribution:** We will assume that the salaries of the employees are normally distributed.\n",
    "\n",
    "- **Population Variance:** For our case, the population variance is known. They are:\n",
    "\n",
    "    - White Employees: $\\$$ 1,136,728,018.03\n",
    "    - Non-white Employees: $\\$$ 1,225,049,916.30\n",
    "    \n",
    "- **Sides:** Since the hypothesis checks for equality it is a two-sided test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92da0557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be6eb84a",
   "metadata": {},
   "source": [
    "### Task 1 - Analyze the dataset (White employees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af6fb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "white_employees = pd.read_excel('employee_salary.xlsx', sheet_name='White').dropna(subset=['Salary'])\n",
    "white_employees.info()\n",
    "white_employees.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca2a127",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_bins = 20\n",
    "interval_range = (np.max(white_employees['Salary']) - np.min(white_employees['Salary']))/total_bins\n",
    "print(f\"Interval range: {interval_range}\")\n",
    "\n",
    "if mode == 'colab':\n",
    "    configure_plotly_browser_state()\n",
    "    \n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=white_employees['Salary'], nbinsx=total_bins,\n",
    "                           name='Histogram', marker_line=dict(color='black', width=1)))\n",
    "\n",
    "# Set the chart title and axis labels\n",
    "fig.update_layout(title='White Employee Salary Distribution',\n",
    "                  xaxis=dict(title='Salary range'),\n",
    "                  yaxis=dict(title='Frequency'))\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf1ef25",
   "metadata": {},
   "source": [
    "From the above dataset, we can see that :\n",
    "\n",
    "- There are 112 white employees.\n",
    "\n",
    "- Most white employees are paid annual salary that is less than $\\$$ 50,000. \n",
    "\n",
    "- Only five employees are paid an annual salary greater than $\\$$ 120,000. \n",
    "\n",
    "- The mean salary of white employees is $\\$$ 70,917 and the standard deviation is $\\$$ 35,000. \n",
    "\n",
    "If we take a look at the employees who get paid more than $\\$$ 120,000, we can see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e817acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "white_employees[white_employees['Salary'] >= 120_000].sort_values(by=['Salary'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e01e1e1",
   "metadata": {},
   "source": [
    "We can see that the highest paid white employees are CEO, CIO, IT Manager, and Director of Sales.\n",
    "\n",
    "### Task 2 - Analyze the dataset (Non-White employees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbff4f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonwhite_employees = pd.read_excel('employee_salary.xlsx', sheet_name='Nonwhite').dropna(subset=['Salary'])\n",
    "nonwhite_employees.info()\n",
    "nonwhite_employees.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edc9320",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_bins = 20\n",
    "interval_range = (np.max(nonwhite_employees['Salary']) - np.min(nonwhite_employees['Salary']))/total_bins\n",
    "print(f\"Interval range: {interval_range}\")\n",
    "\n",
    "if mode == 'colab':\n",
    "    configure_plotly_browser_state()\n",
    "    \n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=nonwhite_employees['Salary'], nbinsx=total_bins,\n",
    "                           name='Histogram', marker_line=dict(color='black', width=1)))\n",
    "\n",
    "# Set the chart title and axis labels\n",
    "fig.update_layout(title='Non-White Employee Salary Distribution',\n",
    "                  xaxis=dict(title='Salary range'),\n",
    "                  yaxis=dict(title='Frequency'))\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e99c9a6",
   "metadata": {},
   "source": [
    "From the above dataset, we can see that :\n",
    "\n",
    "- There are 62 non-white employees.\n",
    "\n",
    "- Most non-white employees are paid annual salary that is less than $\\$$ 60,000. \n",
    "\n",
    "- Only three employees are paid an annual salary greater than $\\$$ 120,000. \n",
    "\n",
    "- The mean salary of white employees is $\\$$ 70,917 and the standard deviation is $\\$$ 35,000. \n",
    "\n",
    "If we take a look at the employees who get paid more than $\\$$ 120,000, we can see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd06992",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonwhite_employees[nonwhite_employees['Salary'] >= 120_000].sort_values(by=['Salary'], ascending=False).head(22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67024b0b",
   "metadata": {},
   "source": [
    "We can see that the highest paid white employees are IT Director, IT Manager, and Director of Operations.\n",
    "\n",
    "### Task 3 - Comparison between the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17202616",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_salaries = list(white_employees['Salary']) + list(nonwhite_employees['Salary'])\n",
    "mean_salary = np.mean(all_salaries)\n",
    "median_salary = np.median(all_salaries)\n",
    "std_deviation_salary = np.std(all_salaries)\n",
    "\n",
    "print(f\"Mean: {mean_salary:.2f}, Median: {median_salary:.2f}, Standard Deviation: {std_deviation_salary:.2f}\")\n",
    "\n",
    "total_bins = 20\n",
    "interval_range = (np.max(all_salaries) - np.min(all_salaries))/total_bins\n",
    "print(f\"Interval range: {interval_range}\")\n",
    "\n",
    "if mode == 'colab':\n",
    "    configure_plotly_browser_state()\n",
    "    \n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=all_salaries, nbinsx=total_bins,\n",
    "                           name='Histogram', marker_line=dict(color='black', width=1)))\n",
    "\n",
    "# Set the chart title and axis labels\n",
    "fig.update_layout(title='All Salary Distribution',\n",
    "                  xaxis=dict(title='Salary range'),\n",
    "                  yaxis=dict(title='Frequency'))\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3127f5e1",
   "metadata": {},
   "source": [
    "- The mean salary of all employees is $\\$$ 68603 and the median salary is $\\$$ 52,000. Therefore, both white and non-white employees, on average are paid less than the mean salary. The graph is right-skewed.\n",
    "\n",
    "- If we consider high salary as the salaries which are more than 1 standard deviation away from the mean, we can calculate the probability of getting paid high salary given that the employee is white and given that the employee is non-white.\n",
    "\n",
    "- If we consider low salary as the salaries that are one standard deviation away to the left of the mean, we can calculate the probability of getting paid low salary given that the employee is white and non-white."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94958e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_salary = mean_salary + std_deviation_salary\n",
    "low_salary = mean_salary - std_deviation_salary\n",
    "\n",
    "probability_high_salary_given_white = len(white_employees[white_employees['Salary'] > high_salary])/len(white_employees)\n",
    "probability_low_salary_given_white = len(white_employees[white_employees['Salary'] < low_salary])/len(white_employees)\n",
    "probability_high_salary_given_nonwhite = len(nonwhite_employees[nonwhite_employees['Salary'] > high_salary])/len(nonwhite_employees)\n",
    "probability_low_salary_given_nonwhite = len(nonwhite_employees[nonwhite_employees['Salary'] < low_salary])/len(nonwhite_employees)\n",
    "\n",
    "print(f\"Probability of getting paid high salary given the employees are white is {probability_high_salary_given_white*100:.2f}%\")\n",
    "print(f\"Probability of getting paid high salary given the employees are non-white is {probability_high_salary_given_nonwhite*100:.2f}%\")\n",
    "print(\"\\n\")\n",
    "print(f\"Probability of getting paid low salary given the employees are white is {probability_low_salary_given_white*100:.2f}%\")\n",
    "print(f\"Probability of getting paid low salary given the employees are non-white is {probability_low_salary_given_nonwhite*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f773383d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_high_salary = len(np.where(all_salaries > high_salary)[0])\n",
    "total_low_salary = len(np.where(all_salaries < low_salary)[0])\n",
    "print(f\"Total employees with high salary: {total_high_salary}\")\n",
    "print(f\"Total employees with low salary: {total_low_salary}\")\n",
    "\n",
    "\n",
    "probability_white_given_high_salary = len(white_employees[white_employees['Salary'] > high_salary])/total_high_salary\n",
    "probability_white_given_low_salary = len(white_employees[white_employees['Salary'] < low_salary])/total_low_salary\n",
    "\n",
    "probability_nonwhite_given_high_salary = len(nonwhite_employees[nonwhite_employees['Salary'] > high_salary])/total_high_salary\n",
    "probability_nonwhite_given_low_salary = len(nonwhite_employees[nonwhite_employees['Salary'] < low_salary])/total_low_salary\n",
    "\n",
    "print(f\"Probability of being white given the employee has high salary: {probability_white_given_high_salary*100:.2f}\")\n",
    "print(f\"Probability of being non-white given the employee has high salary: {probability_nonwhite_given_high_salary*100:.2f}\")\n",
    "print(\"\\n\")\n",
    "print(f\"Probability of being white given the employee has low salary: {probability_white_given_low_salary*100:.2f}\")\n",
    "print(f\"Probability of being non-white given the employee has low salary: {probability_nonwhite_given_low_salary*100:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dcea70",
   "metadata": {},
   "source": [
    "Therefore, even though there is a high probability that an employee will get high salary if they are non-white, currently among the people who are getting paid high salary, the number of white people is greater. Moreover, there is a lower probability that an employee will get low salary if they are non-white. Among the people who are getting paid low salary, the number of white employees are greater. This means that the number of white employees in the company is larger than that of non-white employees. Moreover, the company is moving to reduce pay gap between white and non-white employees.\n",
    "\n",
    "\n",
    "### Task 5 - Hypothesis Testing (Standardization)\n",
    "\n",
    "Since we know the population variance of the samples we may perform the Z-test.\n",
    "\n",
    "The equation to calculate the Z-score of independent samples with known population variance is:\n",
    "\n",
    "\\begin{equation}\n",
    "Z = \\frac{\\bar{x_D} - \\mu_D}{\\sqrt{\\frac{\\sigma^2_W}{n_W} + \\frac{\\sigma^2_N}{n_N}}}\n",
    "\\end{equation}\n",
    "\n",
    "Here,\n",
    "- $\\bar{x_D}$ is equal to $\\bar{x_W} - \\bar{x_N}$\n",
    "\n",
    "- $\\mu_D$ is equal to $\\mu_W - \\mu_N$ which is equal to the estimated mean of our hypothesis i.e. 0.\n",
    "\n",
    "- $\\bar{x_W}$ and $\\bar{x_N}$ are the sample mean of the salaries of white and non-white employees respectively.\n",
    "\n",
    "- $\\sigma^2_W$ and $\\sigma^2_N$ are the population variance of the salaries of white and non-white employees respectively.\n",
    "\n",
    "- $n_W$ and $n_N$ are the sample size of the salaries of white and non-white employees respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775705b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "population_mean_of_interest = 0\n",
    "population_variance_white = 1_136_728_018.03\n",
    "population_variance_nonwhite = 1_225_049_916.30\n",
    "\n",
    "sample_white_mean = np.mean(white_employees['Salary'])\n",
    "sample_nonwhite_mean = np.mean(nonwhite_employees['Salary'])\n",
    "print(f\"Sample Mean - White: {sample_white_mean:.2f}, Non-white: {sample_nonwhite_mean:.2f}\")\n",
    "\n",
    "sample_white_std = np.std(white_employees['Salary'])\n",
    "sample_nonwhite_std = np.std(nonwhite_employees['Salary'])\n",
    "print(f\"Sample standard deviation - White: {sample_white_std:.2f}, Non-white: {sample_nonwhite_std:.2f}\")\n",
    "\n",
    "sample_white_size = len(white_employees)\n",
    "sample_nonwhite_size = len(nonwhite_employees)\n",
    "print(f\"Sample size - White: {sample_white_size}, Non-white: {sample_nonwhite_size}\")\n",
    "\n",
    "\n",
    "standard_error = np.sqrt( (population_variance_white/sample_white_size) + (population_variance_nonwhite/sample_nonwhite_size) )\n",
    "print(f\"Standard Error: {standard_error:.2f}\")\n",
    "\n",
    "z_score = ((sample_white_mean - sample_nonwhite_mean) - population_mean_of_interest)/standard_error\n",
    "print(f\"Z-Score is: {z_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7f4fee",
   "metadata": {},
   "source": [
    "### Task 6 - Hypothesis Testing (Compare Z-score with Critical Value)\n",
    "\n",
    "Now we will calculate the critical value 'z' from the Z-statistics table using a significance level of 0.05. If the z-score is less than -z or greater than +z, then we will reject the null hypothesis. Otherwise, we will accept the null hypothesis. Since, this is a two-tailed test, the data from z-table will be calculated using $1-\\frac{\\alpha}{2}$.\n",
    "\n",
    "**Note**\n",
    "\n",
    "We use the absolute value $|Z|$ of the z-score instead of the actual value since some z-statistics tables do not contain data for negative values and it is easier to compare the positive values. So, if we use the absolute value to calculate the critical value, we can just check whether the z-score is greater than critical value and omit the test for negative range. That is because $-Z < -z$ is the same as $Z > z$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccde73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "critical_value = stats.norm.ppf(1-alpha/2)\n",
    "\n",
    "print(f\"The critical value is {critical_value}\")\n",
    "\n",
    "accepted = np.abs(z_score) <= np.abs(critical_value)\n",
    "result = \"accept\" if accepted else \"reject\"\n",
    "result_range = \"within\" if accepted else \"outside\"\n",
    "print(f\"The z-score is {result_range} the range of critical value. So, with a significance level of {alpha*100}%, we {result} the null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaefc7e",
   "metadata": {},
   "source": [
    "Since the critical value is lower than the z-score we can accept the null hypothesis. Therefore, we can conclude that there is no pay gap between the employees based on ethnicity.\n",
    "\n",
    "### Task 7 - Hypothesis Testing (P-Value)\n",
    "\n",
    "The Z-score is -0.66. So, we find the cell whose sum of row and column header equal to the z-score. If we cannot find such value we pick the sum which is nearest to it. Let the value in the cell of the corresponding row and column be 'c'. The p-value is equal to $1-c*2$ since this is a two-sided test. For our case $c=0.2546$. So, the critical value is $1-0.2546*2 =0.491 $\n",
    "\n",
    "Since the p-value is much greater than the significance level, we can conclude that - at all level of significance there is no pay gap between the employees based on ethnicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dbe6ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "914b9a6e",
   "metadata": {},
   "source": [
    "**References:**\n",
    "\n",
    "1. [The Data Science Course: Complete Data Science Bootcamp](https://www.udemy.com/share/101W9c3@oEFxH6jfeF78cKv-RDiIPVbI_iJt7crj25dGEjsiIRt9MbSV8n50dmB7AlanMAikNg==/)\n",
    "\n",
    "2. [Z-Table](https://byjus.com/maths/z-score-table/)\n",
    "\n",
    "3. [T-Table](https://www.sjsu.edu/faculty/gerstman/StatPrimer/t-table.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
